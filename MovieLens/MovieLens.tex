% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{fvextra}
\usepackage[nobottomtitles]{titlesec}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
\titlespacing*{\section}{0pt}{*3}{*2}
\titlespacing*{\subsection}{0pt}{*2}{*1}
\titlespacing*{\subsubsection}{0pt}{*1.5}{*0.5}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={MovieLens},
  pdfauthor={JP Bradley},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{MovieLens}
\author{JP Bradley}
\date{2025-06-22}

\begin{document}
\maketitle

\section{Introduction}\label{introduction}

In today's digital landscape, from e-commerce platforms like Amazon to
streaming services like Netflix, recommender systems are a critical
component for enhancing user experience and driving engagement. They
seek to solve the problem of information overload by intelligently
filtering and predicting a user's potential interest in items they have
not yet encountered. This project directly engages with this challenge
by building and evaluating a movie recommendation system based on the
principles of collaborative filtering.

To accomplish this, we leverage the well-established
\texttt{MovieLens\ 10M} dataset, a public benchmark dataset provided by
the GroupLens research group. This rich dataset contains over 10 million
ratings applied by approximately 71,000 users to nearly 10,000 unique
movies. Each record provides crucial data points for analysis: unique
identifiers for users and movies, a numerical rating on a scale of 0.5
to 5, a UNIX timestamp indicating when the rating was given, and
associated metadata such as movie titles and genres. The fundamental
challenge lies in the inherent sparsity of the data---most users have
rated only a tiny fraction of the available movies, leaving a vast
matrix of unknown preferences that our model must learn to predict.

The primary methodology employed in this analysis is collaborative
filtering, a technique that makes automatic predictions about the
interests of a user by collecting preferences from many other users.
Unlike content-based methods, which would analyze the properties of a
movie such as its genre or director, collaborative filtering relies
solely on historical user-item interaction data. The underlying
assumption is that users who have agreed in the past (e.g., gave similar
ratings to the same movies) are likely to agree in the future. The model
identifies these patterns to predict a user's rating for a new item by
finding a ``neighborhood'' of similar users or, more commonly, by
modeling the intrinsic biases associated with each user (e.g., a user
who tends to give high ratings) and each movie (e.g., a movie that is
universally acclaimed). The structure of the \texttt{MovieLens} dataset,
being a large matrix of user-movie ratings, makes it an ideal candidate
for this approach.

\textbf{Project Objective:}

The principal objective of this project is to develop and validate a
machine learning model that accurately predicts movie ratings. The
success of the model is quantitatively measured by the Root Mean Squared
Error (\texttt{RMSE}), and the primary goal is to minimize this error
metric on a final, unseen hold-out validation set, denoted as
\texttt{final\_holdout\_test}.

The \texttt{RMSE} is a standard metric for regression tasks that
calculates the square root of the average of the squared differences
between predicted and actual ratings. It is chosen for two key reasons:
it heavily penalizes larger errors, making it sensitive to significant
prediction misses, and its value is interpretable in the same units as
the rating itself (i.e., ``stars''). Therefore, a lower \texttt{RMSE}
signifies a model whose predictions are, on average, closer to the true
user ratings. Our methodology will follow an incremental approach,
starting with a simple baseline model and systematically incorporating
more complex factors---such as movie-specific and user-specific
biases---to progressively improve predictive accuracy and achieve the
lowest possible \texttt{RMSE} on the final hold-out set.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Project Overview}\label{project-overview}

\subsection{1. Data Acquisition \&
Preprocessing}\label{data-acquisition-preprocessing}

\subsubsection{1.1 Setting Up the R
Environment}\label{setting-up-the-r-environment}

\paragraph{1.1.2 Installing Required
Packages}\label{installing-required-packages}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# List of required packages for the entire workflow}
\NormalTok{required\_packages }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \StringTok{"tidyverse"}\NormalTok{,    }\CommentTok{\# Data wrangling, plotting, stringr, readr, etc.}
  \StringTok{"caret"}\NormalTok{,        }\CommentTok{\# Machine learning workflow}
  \StringTok{"knitr"}\NormalTok{,        }\CommentTok{\# Dynamic report generation}
  \StringTok{"skimr"}\NormalTok{,        }\CommentTok{\# Data summaries}
  \StringTok{"systemfonts"}\NormalTok{,  }\CommentTok{\# Font handling}
  \StringTok{"kableExtra"}\NormalTok{,   }\CommentTok{\# Table formatting}
  \StringTok{"DiagrammeR"}    \CommentTok{\# Flowcharts and diagrams}
\NormalTok{)}

\CommentTok{\# Install any missing packages}
\ControlFlowTok{for}\NormalTok{(pkg }\ControlFlowTok{in}\NormalTok{ required\_packages) \{}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{require}\NormalTok{(pkg, }\AttributeTok{character.only =} \ConstantTok{TRUE}\NormalTok{)) \{}
    \FunctionTok{install.packages}\NormalTok{(pkg, }\AttributeTok{repos =} \StringTok{"http://cran.us.r{-}project.org"}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

To ensure a fully reproducible and self-contained analysis, the script
begins by programmatically managing its core dependencies,
\texttt{tidyverse} and \texttt{caret}. For each package, the code first
attempts to load it into the R session. If a package is not already
installed on the system, the \texttt{require()} function fails, which in
turn triggers an automatic installation from a specified Comprehensive R
Archive Network (\texttt{CRAN}) repository. This conditional logic
automates the environment setup, guaranteeing that the script can run on
any machine with R installed without requiring manual pre-installation
of these essential packages.

\paragraph{1.1.3 Loading Required
Packages}\label{loading-required-packages}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load all required libraries}
\FunctionTok{library}\NormalTok{(tidyverse)    }\CommentTok{\# Includes dplyr, ggplot2, stringr, readr, etc.}
\FunctionTok{library}\NormalTok{(caret)}
\FunctionTok{library}\NormalTok{(knitr)}
\FunctionTok{library}\NormalTok{(skimr)}
\FunctionTok{library}\NormalTok{(systemfonts)}
\FunctionTok{library}\NormalTok{(kableExtra)}
\FunctionTok{library}\NormalTok{(DiagrammeR)}
\end{Highlighting}
\end{Shaded}

The analysis and modeling for this project are conducted in R,
leveraging the \texttt{tidyverse} and \texttt{caret} packages to
establish a robust and reproducible data science pipeline. The
\texttt{tidyverse} suite is instrumental in the data wrangling and
exploratory analysis phases. Its packages, particularly \texttt{dplyr}
and \texttt{ggplot2}, enable efficient data manipulation---such as
joining the ratings and movies datasets and engineering new
features---and the creation of insightful visualizations to understand
underlying data distributions. For the modeling phase, the
\texttt{caret} package provides a unified framework for the predictive
modeling workflow. We utilize \texttt{caret} to perform a stratified
split of the data into training and validation sets, to train various
machine learning models with a consistent syntax, and to rigorously
evaluate their performance through cross-validation, using the Root Mean
Squared Error (\texttt{RMSE}) as the primary metric. This combination of
tools provides a seamless transition from raw data exploration to the
development and validation of our final recommendation model.

\subsubsection{1.2 Downloading and Extracting the
Dataset}\label{downloading-and-extracting-the-dataset}

\paragraph{1.2.1 Downloading the Dataset}\label{downloading-the-dataset}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define the filename for the MovieLens 10M dataset zip file}
\NormalTok{dl }\OtherTok{\textless{}{-}} \StringTok{"ml{-}10M100K.zip"}

\CommentTok{\# Check if the file already exists in the current working directory}
\CommentTok{\# If it doesn\textquotesingle{}t, download the dataset zip file from the specified URL and save it with the given filename}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{file.exists}\NormalTok{(dl))}
  \FunctionTok{download.file}\NormalTok{(}\StringTok{"https://files.grouplens.org/datasets/movielens/ml{-}10m.zip"}\NormalTok{, dl)}
\end{Highlighting}
\end{Shaded}

To ensure a self-contained and reproducible workflow, the R script
programmatically manages the data acquisition process. The script first
checks if the dataset's compressed zip archive, \texttt{ml-10M.zip},
already exists in the local working directory. The download from the
specified URL is initiated only if the file is not found. This
conditional logic ensures that the large dataset is not downloaded
redundantly upon subsequent executions of the script.

\paragraph{1.2.2 Extracting the Dataset}\label{extracting-the-dataset}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define the file paths for the ratings and movies data within the extracted folder}
\NormalTok{ratings\_file }\OtherTok{\textless{}{-}} \StringTok{"ml{-}10M100K/ratings.dat"}
\NormalTok{movies\_file  }\OtherTok{\textless{}{-}} \StringTok{"ml{-}10M100K/movies.dat"}

\CommentTok{\# Check if the ratings file exists; if not, extract it from the downloaded zip archive}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{file.exists}\NormalTok{(ratings\_file)) }\FunctionTok{unzip}\NormalTok{(dl, ratings\_file)}

\CommentTok{\# Check if the movies file exists; if not, extract it from the downloaded zip archive}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{file.exists}\NormalTok{(movies\_file)) }\FunctionTok{unzip}\NormalTok{(dl, movies\_file)}
\end{Highlighting}
\end{Shaded}

Following the data acquisition, the script programmatically prepares the
raw data for loading into the R environment. Our analysis specifically
requires the \texttt{ratings.dat} and \texttt{movies.dat} files, which
are contained within the downloaded zip archive. To manage these files
efficiently, the code first checks for the existence of each required
file in the designated project directory. The \texttt{unzip} function is
then called to selectively extract a specific file from the archive only
if it is not already present. This conditional logic streamlines the
data preparation process by avoiding redundant file extraction during
subsequent script executions, ensuring the necessary data is readily
available for analysis without unnecessary overhead.

\subsubsection{1.3 Parsing the Ratings and Movies
Data}\label{parsing-the-ratings-and-movies-data}

\paragraph{1.3.1 Parsing the Ratings
Data}\label{parsing-the-ratings-data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Read the ratings file line by line, splitting each line at \textquotesingle{}::\textquotesingle{} into a matrix{-}like structure}
\NormalTok{ratings }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{str\_split}\NormalTok{(}\FunctionTok{read\_lines}\NormalTok{(ratings\_file), }
                                   \FunctionTok{fixed}\NormalTok{(}\StringTok{"::"}\NormalTok{), }\AttributeTok{simplify =} \ConstantTok{TRUE}\NormalTok{), }
                         \AttributeTok{stringsAsFactors =} \ConstantTok{FALSE}\NormalTok{)}

\CommentTok{\# Rename the columns to meaningful variable names}
\FunctionTok{colnames}\NormalTok{(ratings) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"userId"}\NormalTok{, }\StringTok{"movieId"}\NormalTok{, }\StringTok{"rating"}\NormalTok{, }\StringTok{"timestamp"}\NormalTok{)}

\CommentTok{\# Convert each column to its appropriate data type for analysis}
\NormalTok{ratings }\OtherTok{\textless{}{-}}\NormalTok{ ratings }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{userId =} \FunctionTok{as.integer}\NormalTok{(userId), }
         \AttributeTok{movieId =} \FunctionTok{as.integer}\NormalTok{(movieId), }
         \AttributeTok{rating =} \FunctionTok{as.numeric}\NormalTok{(rating), }
         \AttributeTok{timestamp =} \FunctionTok{as.integer}\NormalTok{(timestamp))}
\end{Highlighting}
\end{Shaded}

The script ingests the raw \texttt{ratings.dat} file, which uses a
non-standard double-colon (::) delimiter. To handle this format, the
data is first read as a vector of text lines, and each line is then
parsed into separate columns using a string-splitting function. The
resulting matrix is converted into a standard R data frame, to which we
assign the descriptive column headers: \texttt{userId},
\texttt{movieId}, \texttt{rating}, and \texttt{timestamp}. In the final
and critical step of this process, we perform data type coercion. The
\texttt{userId}, \texttt{movieId}, and \texttt{timestamp} columns are
converted to integers, and the \texttt{rating} column is converted to a
numeric type to correctly handle fractional values like 3.5. This
procedure transforms the raw text data into a clean, properly typed, and
structured format that is essential for all subsequent computational and
analytical tasks.

\subparagraph{DATA SUMMARY: Cleaned Ratings
Data}\label{data-summary-cleaned-ratings-data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use kable() for a professional{-}looking preview of the data}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
  \FunctionTok{head}\NormalTok{(ratings), }
  \AttributeTok{caption =} \StringTok{"A preview of the first six rows of the ratings data."}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrr@{}}
\caption{A preview of the first six rows of the ratings
data.}\tabularnewline
\toprule\noalign{}
userId & movieId & rating & timestamp \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
userId & movieId & rating & timestamp \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 122 & 5 & 838985046 \\
1 & 185 & 5 & 838983525 \\
1 & 231 & 5 & 838983392 \\
1 & 292 & 5 & 838983421 \\
1 & 316 & 5 & 838983392 \\
1 & 329 & 5 & 838983392 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use skim() for a rich and clean statistical summary}
\FunctionTok{skim}\NormalTok{(ratings)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ll@{}}
\caption{Data summary}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
Name & ratings \\
Number of rows & 10000054 \\
Number of columns & 4 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Column type frequency: & \\
numeric & 4 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Group variables & None \\
\end{longtable}

\textbf{Variable type: numeric}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1102}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0787}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1102}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1024}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1024}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0945}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0787}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1024}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0866}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0866}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0472}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
skim\_variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_missing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
complete\_rate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
mean
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
sd
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p0
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p25
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p50
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p75
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p100
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
hist
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
userId & 0 & 1 & 3.586986e+04 & 20585.34 & 1.0 & 18123 & 35740.5 & 53608
& 71567 & ▇▇▇▇▇ \\
movieId & 0 & 1 & 4.120290e+03 & 8938.40 & 1.0 & 648 & 1834.0 & 3624 &
65133 & ▇▁▁▁▁ \\
rating & 0 & 1 & 3.510000e+00 & 1.06 & 0.5 & 3 & 4.0 & 4 & 5 & ▁▂▆▇▅ \\
timestamp & 0 & 1 & 1.032606e+09 & 115963962.20 & 789652009.0 &
946765880 & 1035476481.0 & 1126749071 & 1231131736 & ▅▆▇▇▆ \\
\end{longtable}

With ratings distributed across a 0.5--5.0 scale and user IDs spanning a
large, heterogeneous population, the dataset supports scalable modeling
of rating behavior and temporal shifts in consumption. Its structure
provides a stable foundation for advancing hybrid recommender
algorithms, behavioral clustering, and fairness-aware personalization
strategies in collaborative filtering research

\paragraph{1.3.2 Parsing the Movies Data}\label{parsing-the-movies-data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Read each line of the movies file, split on the delimiter "::", }
\CommentTok{\# and assemble into a data frame (strings stay as character type)}
\NormalTok{movies }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}
  \FunctionTok{str\_split}\NormalTok{(}
    \FunctionTok{read\_lines}\NormalTok{(movies\_file), }
    \FunctionTok{fixed}\NormalTok{(}\StringTok{"::"}\NormalTok{), }
    \AttributeTok{simplify =} \ConstantTok{TRUE}
\NormalTok{  ), }
  \AttributeTok{stringsAsFactors =} \ConstantTok{FALSE}
\NormalTok{)}

\CommentTok{\# Assign meaningful column names}
\FunctionTok{colnames}\NormalTok{(movies) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"movieId"}\NormalTok{, }\StringTok{"title"}\NormalTok{, }\StringTok{"genres"}\NormalTok{)}

\CommentTok{\# Convert movieId from character to integer for proper joins and filtering}
\NormalTok{movies }\OtherTok{\textless{}{-}}\NormalTok{ movies }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{movieId =} \FunctionTok{as.integer}\NormalTok{(movieId))}
\end{Highlighting}
\end{Shaded}

In parallel with the ratings data, the script loads and processes the
\texttt{movies.dat} file to create a structured lookup table for movie
information. The process mirrors the handling of the ratings file, first
ingesting the raw text lines and then parsing each line based on the
double-colon (::) delimiter to separate the distinct data fields. This
parsed data is converted into a data frame, and its columns are
programmatically named \texttt{movieId}, \texttt{title}, and
\texttt{genres}. To ensure data integrity and to enable correct matching
with the ratings data, the \texttt{movieId} column is explicitly
converted from a character string to an integer type. This structured
movies table is essential, as it provides the critical mapping between a
\texttt{movieId} and its corresponding title and genre information for
our analysis.

\subparagraph{DATA SUMMARY: Cleaned Movies
Data}\label{data-summary-cleaned-movies-data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use kable() for a professional{-}looking preview of the data}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
  \FunctionTok{head}\NormalTok{(movies), }
  \AttributeTok{caption =} \StringTok{"A preview of the first six rows of the movies data."}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.0748}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3271}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.5981}}@{}}
\caption{A preview of the first six rows of the movies
data.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
movieId
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
title
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
genres
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
movieId
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
title
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
genres
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & Toy Story (1995) &
Adventure\textbar Animation\textbar Children\textbar Comedy\textbar Fantasy \\
2 & Jumanji (1995) & Adventure\textbar Children\textbar Fantasy \\
3 & Grumpier Old Men (1995) & Comedy\textbar Romance \\
4 & Waiting to Exhale (1995) & Comedy\textbar Drama\textbar Romance \\
5 & Father of the Bride Part II (1995) & Comedy \\
6 & Heat (1995) & Action\textbar Crime\textbar Thriller \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use skim() for a rich and clean statistical summary}
\FunctionTok{skim}\NormalTok{(movies)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ll@{}}
\caption{Data summary}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
Name & movies \\
Number of rows & 10681 \\
Number of columns & 3 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Column type frequency: & \\
character & 2 \\
numeric & 1 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Group variables & None \\
\end{longtable}

\textbf{Variable type: character}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1944}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1389}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1944}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0556}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0556}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1528}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
skim\_variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_missing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
complete\_rate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
min
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
max
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
empty
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_unique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
whitespace
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
title & 0 & 1 & 8 & 160 & 0 & 10680 & 0 \\
genres & 0 & 1 & 3 & 60 & 0 & 797 & 0 \\
\end{longtable}

\textbf{Variable type: numeric}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1628}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1163}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1628}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1047}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1047}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0349}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0581}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0581}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0581}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0698}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0698}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
skim\_variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_missing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
complete\_rate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
mean
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
sd
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p0
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p25
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p50
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p75
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p100
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
hist
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
movieId & 0 & 1 & 13120.52 & 17808.85 & 1 & 2755 & 5436 & 8713 & 65133 &
▇▁▁▁▁ \\
\end{longtable}

The movies metadata infuses content-based context---via genre ontologies
and item-level identifiers---into user behavior modeling. This
integration enables the development of hybrid recommender systems that
align user preferences with interpretable item features, enhancing
algorithmic personalization, fairness, and scalability.

\subsubsection{1.4 Merging Ratings and Movies
Data}\label{merging-ratings-and-movies-data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Combine user ratings with movie metadata into one comprehensive table:}
\CommentTok{\# – left\_join preserves every rating record (even if some movies lack metadata)}
\CommentTok{\# – appends title and genres columns to each rating}
\CommentTok{\# Result: movielens has userId, movieId, rating, timestamp, title, and genres}
\NormalTok{movielens }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(ratings, movies, }\AttributeTok{by =} \StringTok{"movieId"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

To create a single, comprehensive dataset for analysis, the ratings and
movies data frames are merged using a \texttt{left\_join} operation.
This function links the two tables by matching rows that share a common
\texttt{movieId}. The result is a new, unified data frame named
\texttt{movielens}, where each rating record is now enriched with the
corresponding movie's title and genres. This combined dataset is the
foundational data structure for all subsequent exploratory analysis,
feature engineering, and model training, as it contains all the
necessary user, movie, and rating information in a single, tidy format.

\subparagraph{DATA SUMMARY: Merged Data}\label{data-summary-merged-data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use kable() for a professional{-}looking preview of the data}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
  \FunctionTok{head}\NormalTok{(movielens), }
  \AttributeTok{caption =} \StringTok{"A preview of the first six rows of the combined data."}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0654}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0748}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0654}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0935}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.2804}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.4206}}@{}}
\caption{A preview of the first six rows of the combined
data.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
userId
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
movieId
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
rating
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
timestamp
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
title
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
genres
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
userId
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
movieId
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
rating
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
timestamp
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
title
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
genres
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 122 & 5 & 838985046 & Boomerang (1992) & Comedy\textbar Romance \\
1 & 185 & 5 & 838983525 & Net, The (1995) &
Action\textbar Crime\textbar Thriller \\
1 & 231 & 5 & 838983392 & Dumb \& Dumber (1994) & Comedy \\
1 & 292 & 5 & 838983421 & Outbreak (1995) &
Action\textbar Drama\textbar Sci-Fi\textbar Thriller \\
1 & 316 & 5 & 838983392 & Stargate (1994) &
Action\textbar Adventure\textbar Sci-Fi \\
1 & 329 & 5 & 838983392 & Star Trek: Generations (1994) &
Action\textbar Adventure\textbar Drama\textbar Sci-Fi \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use skim() for a rich and clean statistical summary}
\FunctionTok{skim}\NormalTok{(movielens)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ll@{}}
\caption{Data summary}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
Name & movielens \\
Number of rows & 10000054 \\
Number of columns & 6 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Column type frequency: & \\
character & 2 \\
numeric & 4 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Group variables & None \\
\end{longtable}

\textbf{Variable type: character}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1944}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1389}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1944}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0556}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0556}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 14\tabcolsep) * \real{0.1528}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
skim\_variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_missing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
complete\_rate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
min
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
max
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
empty
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_unique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
whitespace
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
title & 0 & 1 & 8 & 160 & 0 & 10676 & 0 \\
genres & 0 & 1 & 3 & 60 & 0 & 797 & 0 \\
\end{longtable}

\textbf{Variable type: numeric}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1102}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0787}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1102}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1024}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1024}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0945}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0787}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1024}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0866}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0866}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0472}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
skim\_variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_missing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
complete\_rate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
mean
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
sd
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p0
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p25
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p50
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p75
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p100
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
hist
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
userId & 0 & 1 & 3.586986e+04 & 20585.34 & 1.0 & 18123 & 35740.5 & 53608
& 71567 & ▇▇▇▇▇ \\
movieId & 0 & 1 & 4.120290e+03 & 8938.40 & 1.0 & 648 & 1834.0 & 3624 &
65133 & ▇▁▁▁▁ \\
rating & 0 & 1 & 3.510000e+00 & 1.06 & 0.5 & 3 & 4.0 & 4 & 5 & ▁▂▆▇▅ \\
timestamp & 0 & 1 & 1.032606e+09 & 115963962.20 & 789652009.0 &
946765880 & 1035476481.0 & 1126749071 & 1231131736 & ▅▆▇▇▆ \\
\end{longtable}

The movielens dataset constitutes a temporally indexed, user-item
interaction matrix enriched with item-level covariates (title, year,
genres) and user-specific behavioral data (userId, rating, timestamp).
Its schema supports advanced modeling tasks including matrix
factorization with side information, dynamic collaborative filtering,
and hierarchical genre-aware embeddings. By unifying observational
feedback with content-based taxonomies, it facilitates research into
high-dimensional preference estimation, temporal drift in item
relevance, and fine-grained regularization strategies for recommender
architectures.

\subsubsection{1.5 Final Hold-out Test Set
Preparation}\label{final-hold-out-test-set-preparation}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# STEP 1: Create a reproducible 10\% hold‐out sample from the full movielens data}
\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# Set a random seed so that anyone running this code will get the same split.}
\CommentTok{\# For R ≥ 3.6, you need sample.kind = "Rounding" to replicate older behavior;}
\CommentTok{\# if you’re on R ≤ 3.5, just use set.seed(1).}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{sample.kind =} \StringTok{"Rounding"}\NormalTok{)}

\CommentTok{\# createDataPartition() returns row indices for a stratified sample of ratings.}
\CommentTok{\# Here p = 0.1 means “take 10\% of the rows” while preserving the rating distribution.}
\NormalTok{test\_index }\OtherTok{\textless{}{-}} \FunctionTok{createDataPartition}\NormalTok{(}
  \AttributeTok{y     =}\NormalTok{ movielens}\SpecialCharTok{$}\NormalTok{rating,  }\CommentTok{\# the outcome we want to stratify by}
  \AttributeTok{times =} \DecValTok{1}\NormalTok{,                  }\CommentTok{\# only one partition}
  \AttributeTok{p     =} \FloatTok{0.1}\NormalTok{,                }\CommentTok{\# proportion in the hold‐out set}
  \AttributeTok{list  =} \ConstantTok{FALSE}               \CommentTok{\# return a vector, not a list}
\NormalTok{)}

\CommentTok{\# Split the data:}
\CommentTok{\# – edx    : 90\% of the data, to train and tune our models}
\CommentTok{\# – temp   : initial 10\% hold‐out, which we’ll prune next}
\NormalTok{edx  }\OtherTok{\textless{}{-}}\NormalTok{ movielens[}\SpecialCharTok{{-}}\NormalTok{test\_index, ]}
\NormalTok{temp }\OtherTok{\textless{}{-}}\NormalTok{ movielens[test\_index, ]}

\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# STEP 2: Guarantee that the final test set only contains users and movies seen}
\CommentTok{\#            during training (so we aren’t forced to predict on unseen data).}
\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# semi\_join(x, y, by) keeps only rows in x that have matching keys in y.}
\NormalTok{final\_holdout\_test }\OtherTok{\textless{}{-}}\NormalTok{ temp }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{semi\_join}\NormalTok{(edx, }\AttributeTok{by =} \StringTok{"movieId"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# drop any ratings for brand‐new movies}
  \FunctionTok{semi\_join}\NormalTok{(edx, }\AttributeTok{by =} \StringTok{"userId"}\NormalTok{)       }\CommentTok{\# drop any ratings from brand‐new users}

\CommentTok{\# Any rows from temp that got dropped because of unseen user/movie:}
\NormalTok{removed }\OtherTok{\textless{}{-}} \FunctionTok{anti\_join}\NormalTok{(temp, final\_holdout\_test)}

\CommentTok{\# Put those removed rows back into the edx (training) set to preserve all data.}
\NormalTok{edx }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(edx, removed)}

\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# STEP 3: Clean up workspace}
\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# Remove files and objects we no longer need to free up memory}
\FunctionTok{rm}\NormalTok{(dl, ratings, movies, test\_index, temp, movielens, removed)}
\end{Highlighting}
\end{Shaded}

To rigorously evaluate the final model's performance, we partition the
complete \texttt{movielens} dataset into a primary training set
(\texttt{edx}) and a final hold-out validation set
(\texttt{final\_holdout\_test}). To ensure this process is reproducible,
we first set a random seed. Using the \texttt{createDataPartition}
function, we perform an initial 90/10 stratified split based on the
rating outcome, which preserves the rating distribution in both sets.
However, a critical step is then taken to address a common challenge in
recommendation systems: ensuring the validation set only contains users
and movies that are also present in the training set. We achieve this by
filtering the hold-out set using \texttt{semi\_join} operations, which
guarantees that every \texttt{userId} and \texttt{movieId} in the final
\texttt{final\_holdout\_test} set also exists in the \texttt{edx} set.
To maintain data integrity, any rows removed from the hold-out set
during this process are identified and added back to the \texttt{edx}
training set. Finally, all intermediate data objects are removed from
the environment to ensure a clean workspace, leaving only the final,
well-defined training and validation sets for the modeling phase.

\section{Methodologies}\label{methodologies}

\subsection{1. Executive Summary}\label{executive-summary}

This capstone project presents a full machine learning workflow aimed at
developing a fairness-aware movie recommender system using the MovieLens
dataset. The project integrates data preprocessing, bias auditing,
exploratory data analysis, feature engineering, ensemble modeling, and
rigorous evaluation practices to ensure both predictive accuracy and
ethical system design.

The data wrangling phase involved parsing key structural
variables---such as user IDs, movie IDs, timestamps, ratings, and genre
labels---into clean, structured formats ready for analysis. This step
included handling duplicates, parsing titles to extract release years,
converting timestamps to date-based formats, and encoding multi-genre
fields using multi-hot and long-format transformations. These
preprocessing steps ensured consistency, addressed data quality issues,
and laid the foundation for downstream modeling.

A targeted bias audit evaluated potential structural imbalances that
could influence the fairness of recommendations. Key areas of
investigation included user and item participation distributions,
popularity bias, and underrepresentation of specific genres or
low-frequency users. Correlations between rating count and average
rating were examined to quantify skew, while segment-specific
behaviors---such as those exhibited by new or infrequent users---were
analyzed for divergence from global trends.

Exploratory data analysis revealed significant temporal, behavioral, and
content-based patterns. Visualizations of rating distributions, user
activity trends, and genre preferences across time informed hypothesis
generation and feature construction. In particular, variations in
average rating by genre and release decade pointed to the importance of
incorporating both content and user history into predictive models.

Feature engineering centered on deriving interpretable, high-value
predictors. Time-based variables such as movie age, user tenure, and
rating year were introduced alongside behavior-derived indicators like
binned user/movie activity levels and normalized ratings. Outlier
detection methods flagged anomalous or inconsistent raters, adding
another layer of quality control before modeling.

A suite of supervised machine learning models was developed to learn
user preferences and predict ratings. These included regularized linear
regressors (Ridge, Lasso), tree-based models (e.g., random forests and
gradient boosting), and matrix factorization approaches. Each model was
supported by a modular preprocessing pipeline and trained using k-fold
cross-validation to estimate generalization performance. Regularization
and complexity control techniques were applied to mitigate overfitting
and improve robustness.

Ensemble modeling formed a core component of the system, leveraging both
stacking and blending strategies to combine base learner outputs.
Meta-models trained on out-of-fold predictions improved accuracy by
capturing complementary strengths across model families. Ensemble
performance consistently outpaced individual models when evaluated on
holdout sets.

Model evaluation utilized both regression-based (RMSE, MAE) and
ranking-based (\href{mailto:precision@K}{\nolinkurl{precision@K}}, NDCG)
metrics to holistically assess prediction quality. Results were
tabulated and visualized to highlight performance trade-offs and
document ensemble improvements. These metrics provided insight into both
the raw predictive capability and the ranking precision of the
recommender system.

Finally, the entire pipeline---from preprocessing to evaluation---was
implemented in a reproducible framework using R Markdown. Code,
parameters, and results were version-controlled and documented, enabling
complete transparency for peer review and future iteration. The end
result is a high-performing, explainable, and fair recommendation engine
grounded in best practices for responsible machine learning.

\subsection{2. Work-Flow}\label{work-flow}

\includegraphics{MovieLens_files/figure-latex/workflow-1.pdf}

\end{document}
